{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 4  - Competencia: Clasificación de Peptidos Antimicrobianos\n",
    "\n",
    "Se cuenta con una recopilación de bases de datos de *péptidos* de dos tipos: *antimicrobianos* y *No antimicrobianos*. Para cada conjunto de datos se tienen 1700 descriptores o características fisicoquímicas de los *péptidos*. \n",
    "El objetivo de este Notebook es realizar un proceso de clasificación de los péptidos de ambas clases empleando 3 métodos de clasificación: Regresión Logística, Bosque Aleatorio y Descenso de Gradiente Estocástico. Para ello se dividirá la base de datos en un 80% para entrenamiento y 20% para probar los modelos. \n",
    "\n",
    "El procedimiento de trabajo es el siguiente:\n",
    "1. Se realizará el proceso de clasificación con todas las características.\n",
    "2. Se aplicará un proceso de eliminación de características recursivo para extraer las características más importantes.\n",
    "3. Se aplicará un método de extracción de características.\n",
    "\n",
    "En cada paso de medirán diferentes métricas para evaluar el desempeño de los clasificadores.\n",
    "\n",
    "\n",
    "Los integrates del grupo son:\n",
    "- Lina Victoria Parra Duque\n",
    "- Janick Alberto Reales Salas\n",
    "- Luisa Fernanda Rios Piedrahita\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación con todas las características\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se importan algunas librerías requeridas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a cargar las bases de datos de péptidos a emplear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8322, 1760)\n",
      "(13679, 1760)\n",
      "(1623, 1761)\n"
     ]
    }
   ],
   "source": [
    "## Base de datos positivos (peptidos antimicrobianos)\n",
    "positivos = pd.read_csv(\"DatosPositivos2.csv\", index_col = 0)\n",
    "\n",
    "## Base de datos negativos (peptidos no antimicrobianos)\n",
    "negativos = pd.read_csv(\"DatosNegativos2.csv\")\n",
    "\n",
    "## Conjunto de validación\n",
    "validacion = pd.read_csv(\"DatosValidacion2.csv\", index_col = 0)\n",
    "\n",
    "print(positivos.shape)\n",
    "print(negativos.shape)\n",
    "print(validacion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sequence', 'length', 'molecular_weight', 'charge', 'charge_density',\n",
      "       'isoelectric_point', 'gravy', 'instability_index', 'aromaticity',\n",
      "       'aliphatic_index',\n",
      "       ...\n",
      "       'embed_2_91', 'embed_2_92', 'embed_2_93', 'embed_2_94', 'embed_2_95',\n",
      "       'embed_2_96', 'embed_2_97', 'embed_2_98', 'embed_2_99', 'class'],\n",
      "      dtype='object', length=1760)\n",
      "Index(['sequence', 'length', 'molecular_weight', 'charge', 'charge_density',\n",
      "       'isoelectric_point', 'gravy', 'instability_index', 'aromaticity',\n",
      "       'aliphatic_index',\n",
      "       ...\n",
      "       'embed_2_91', 'embed_2_92', 'embed_2_93', 'embed_2_94', 'embed_2_95',\n",
      "       'embed_2_96', 'embed_2_97', 'embed_2_98', 'embed_2_99', 'class'],\n",
      "      dtype='object', length=1760)\n",
      "Index(['Unnamed: 0.1', 'sequence', 'length', 'molecular_weight', 'charge',\n",
      "       'charge_density', 'isoelectric_point', 'gravy', 'instability_index',\n",
      "       'aromaticity',\n",
      "       ...\n",
      "       'embed_2_91', 'embed_2_92', 'embed_2_93', 'embed_2_94', 'embed_2_95',\n",
      "       'embed_2_96', 'embed_2_97', 'embed_2_98', 'embed_2_99', 'class'],\n",
      "      dtype='object', length=1761)\n"
     ]
    }
   ],
   "source": [
    "## Verificamos las características contenidas en cada base de datos\n",
    "print(positivos.columns)\n",
    "print(negativos.columns)\n",
    "print(validacion.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos de validación contiene una columba extra (Unnamed: 0.1) con los índices, por lo que se procede a eliminarla para que los tres conjuntos de datos cuenten con el mismo número de columnas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1623, 1760)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>length</th>\n",
       "      <th>molecular_weight</th>\n",
       "      <th>charge</th>\n",
       "      <th>charge_density</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>gravy</th>\n",
       "      <th>instability_index</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>aliphatic_index</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_2_91</th>\n",
       "      <th>embed_2_92</th>\n",
       "      <th>embed_2_93</th>\n",
       "      <th>embed_2_94</th>\n",
       "      <th>embed_2_95</th>\n",
       "      <th>embed_2_96</th>\n",
       "      <th>embed_2_97</th>\n",
       "      <th>embed_2_98</th>\n",
       "      <th>embed_2_99</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>VVCACRRALCLPRERRAGFCRIRGRIHPLCCRR</td>\n",
       "      <td>33</td>\n",
       "      <td>3897.77</td>\n",
       "      <td>8.691</td>\n",
       "      <td>0.002230</td>\n",
       "      <td>11.404358</td>\n",
       "      <td>-0.112121</td>\n",
       "      <td>84.766667</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>85.757576</td>\n",
       "      <td>...</td>\n",
       "      <td>2.771416</td>\n",
       "      <td>-0.851930</td>\n",
       "      <td>-0.459909</td>\n",
       "      <td>0.909622</td>\n",
       "      <td>1.402783</td>\n",
       "      <td>-3.848056</td>\n",
       "      <td>-0.528822</td>\n",
       "      <td>-0.740751</td>\n",
       "      <td>-0.257650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>GICACRRRFCPNSERFSGYCRVNGARYVRCCSRR</td>\n",
       "      <td>34</td>\n",
       "      <td>4003.64</td>\n",
       "      <td>7.590</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>10.196106</td>\n",
       "      <td>-0.638235</td>\n",
       "      <td>76.035294</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>34.411765</td>\n",
       "      <td>...</td>\n",
       "      <td>2.356963</td>\n",
       "      <td>-0.590644</td>\n",
       "      <td>-0.433246</td>\n",
       "      <td>0.362768</td>\n",
       "      <td>1.204798</td>\n",
       "      <td>-3.838024</td>\n",
       "      <td>-0.859893</td>\n",
       "      <td>-1.086264</td>\n",
       "      <td>0.052278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LRDLVCYCRSRGCKGRERMNGTCRKGHLLYTLCCR</td>\n",
       "      <td>35</td>\n",
       "      <td>4121.92</td>\n",
       "      <td>6.689</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>9.611023</td>\n",
       "      <td>-0.551429</td>\n",
       "      <td>16.851429</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.762231</td>\n",
       "      <td>-1.182640</td>\n",
       "      <td>-0.908285</td>\n",
       "      <td>0.802487</td>\n",
       "      <td>1.546229</td>\n",
       "      <td>-4.543212</td>\n",
       "      <td>-0.786475</td>\n",
       "      <td>-0.477468</td>\n",
       "      <td>-0.178319</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RRCICTTRTCRFPYRRLGTCIFQNRVYTFCC</td>\n",
       "      <td>31</td>\n",
       "      <td>3838.56</td>\n",
       "      <td>6.589</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>9.802917</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>53.977419</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>47.096774</td>\n",
       "      <td>...</td>\n",
       "      <td>1.742604</td>\n",
       "      <td>-0.981736</td>\n",
       "      <td>-0.098695</td>\n",
       "      <td>0.614634</td>\n",
       "      <td>0.774174</td>\n",
       "      <td>-2.818301</td>\n",
       "      <td>-0.395545</td>\n",
       "      <td>-0.738405</td>\n",
       "      <td>0.369630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>VCSCRLVFCRRTELRVGNCLIGGVSFTYCCTRV</td>\n",
       "      <td>33</td>\n",
       "      <td>3715.45</td>\n",
       "      <td>3.591</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>8.981384</td>\n",
       "      <td>0.660606</td>\n",
       "      <td>62.042424</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>91.212121</td>\n",
       "      <td>...</td>\n",
       "      <td>1.734715</td>\n",
       "      <td>-0.830263</td>\n",
       "      <td>-0.386610</td>\n",
       "      <td>0.836167</td>\n",
       "      <td>0.859871</td>\n",
       "      <td>-3.665342</td>\n",
       "      <td>-0.922017</td>\n",
       "      <td>-0.364447</td>\n",
       "      <td>-0.055827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1760 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sequence  length  molecular_weight  charge  \\\n",
       "0    VVCACRRALCLPRERRAGFCRIRGRIHPLCCRR      33           3897.77   8.691   \n",
       "1   GICACRRRFCPNSERFSGYCRVNGARYVRCCSRR      34           4003.64   7.590   \n",
       "2  LRDLVCYCRSRGCKGRERMNGTCRKGHLLYTLCCR      35           4121.92   6.689   \n",
       "3      RRCICTTRTCRFPYRRLGTCIFQNRVYTFCC      31           3838.56   6.589   \n",
       "4    VCSCRLVFCRRTELRVGNCLIGGVSFTYCCTRV      33           3715.45   3.591   \n",
       "\n",
       "   charge_density  isoelectric_point     gravy  instability_index  \\\n",
       "0        0.002230          11.404358 -0.112121          84.766667   \n",
       "1        0.001896          10.196106 -0.638235          76.035294   \n",
       "2        0.001623           9.611023 -0.551429          16.851429   \n",
       "3        0.001717           9.802917 -0.200000          53.977419   \n",
       "4        0.000967           8.981384  0.660606          62.042424   \n",
       "\n",
       "   aromaticity  aliphatic_index  ...  embed_2_91  embed_2_92  embed_2_93  \\\n",
       "0     0.030303        85.757576  ...    2.771416   -0.851930   -0.459909   \n",
       "1     0.117647        34.411765  ...    2.356963   -0.590644   -0.433246   \n",
       "2     0.057143        64.000000  ...    2.762231   -1.182640   -0.908285   \n",
       "3     0.161290        47.096774  ...    1.742604   -0.981736   -0.098695   \n",
       "4     0.090909        91.212121  ...    1.734715   -0.830263   -0.386610   \n",
       "\n",
       "   embed_2_94  embed_2_95  embed_2_96  embed_2_97  embed_2_98  embed_2_99  \\\n",
       "0    0.909622    1.402783   -3.848056   -0.528822   -0.740751   -0.257650   \n",
       "1    0.362768    1.204798   -3.838024   -0.859893   -1.086264    0.052278   \n",
       "2    0.802487    1.546229   -4.543212   -0.786475   -0.477468   -0.178319   \n",
       "3    0.614634    0.774174   -2.818301   -0.395545   -0.738405    0.369630   \n",
       "4    0.836167    0.859871   -3.665342   -0.922017   -0.364447   -0.055827   \n",
       "\n",
       "   class  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 1760 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Se elimina columna con índice de datos de validación\n",
    "\n",
    "validacion = validacion.iloc[:, 1:]\n",
    "print(validacion.shape)\n",
    "validacion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo siguiente a hacer es unir las bases de datos en una sola llamada \"*database*\", para posteriormente separar la primera columna, la cual contiene los nombres de cada secuencia de péptidos y no es relevate para el proceso de clasificación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## se concatenan las bases\n",
    "\n",
    "database = pd.concat([positivos, negativos, validacion], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23624, 1759)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se elimina columna de texto:\n",
    "\n",
    "sequence = database['sequence']\n",
    "database = database.iloc[:, 1:]\n",
    "database.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora separamos la columna del target/clase del conjunto de características para aplicar un proceso de *normalización* sobre este último. Con esta normalización queremos llevar todas las características a una misma escala, que permita un mejor desempeño de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se divide la base de datos\n",
    "\n",
    "data = database.iloc[:, :-1] # conjunto de carasterísticas\n",
    "columnas = data.columns      # nombres de las columnas/características\n",
    "target = database['class']   # clase de los péptidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se aplica normalización sobre el conjunto de características\n",
    "\n",
    "data_norm = preprocessing.normalize(data, norm='l2', axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>molecular_weight</th>\n",
       "      <th>charge</th>\n",
       "      <th>charge_density</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>gravy</th>\n",
       "      <th>instability_index</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>aliphatic_index</th>\n",
       "      <th>boman_index</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_2_90</th>\n",
       "      <th>embed_2_91</th>\n",
       "      <th>embed_2_92</th>\n",
       "      <th>embed_2_93</th>\n",
       "      <th>embed_2_94</th>\n",
       "      <th>embed_2_95</th>\n",
       "      <th>embed_2_96</th>\n",
       "      <th>embed_2_97</th>\n",
       "      <th>embed_2_98</th>\n",
       "      <th>embed_2_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>0.010263</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>-0.009469</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003859</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>-0.002609</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>-0.005448</td>\n",
       "      <td>-0.000517</td>\n",
       "      <td>-0.008588</td>\n",
       "      <td>0.001712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>0.006535</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>-0.002086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001741</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>-0.007457</td>\n",
       "      <td>-0.005970</td>\n",
       "      <td>-0.001380</td>\n",
       "      <td>-0.001512</td>\n",
       "      <td>-0.003999</td>\n",
       "      <td>-0.005291</td>\n",
       "      <td>-0.003582</td>\n",
       "      <td>-0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>0.005955</td>\n",
       "      <td>0.010550</td>\n",
       "      <td>0.010414</td>\n",
       "      <td>0.009411</td>\n",
       "      <td>-0.004293</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.009523</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001257</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.005131</td>\n",
       "      <td>-0.001131</td>\n",
       "      <td>0.013715</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>-0.009549</td>\n",
       "      <td>-0.006825</td>\n",
       "      <td>-0.006487</td>\n",
       "      <td>0.005322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.004047</td>\n",
       "      <td>0.008327</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006106</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.006760</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>-0.006340</td>\n",
       "      <td>-0.005677</td>\n",
       "      <td>-0.006845</td>\n",
       "      <td>0.006009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.007743</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.002832</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013453</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>-0.016623</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.008107</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>-0.010720</td>\n",
       "      <td>-0.009756</td>\n",
       "      <td>-0.016503</td>\n",
       "      <td>-0.000963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1758 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     length  molecular_weight    charge  charge_density  isoelectric_point  \\\n",
       "0  0.006130          0.005887  0.010263        0.010246           0.007871   \n",
       "1  0.005162          0.004815  0.006535        0.007977           0.008063   \n",
       "2  0.005485          0.005955  0.010550        0.010414           0.009411   \n",
       "3  0.006453          0.006128  0.004216        0.004044           0.008480   \n",
       "4  0.008066          0.007743  0.001172        0.000890           0.006037   \n",
       "\n",
       "      gravy  instability_index  aromaticity  aliphatic_index  boman_index  \\\n",
       "0 -0.009469           0.008451     0.006390         0.000000     0.009508   \n",
       "1  0.006413           0.002421     0.000000         0.010008    -0.002086   \n",
       "2 -0.004293           0.004986     0.009523         0.003307     0.004552   \n",
       "3  0.003143           0.001968     0.004047         0.008327     0.001710   \n",
       "4  0.002832           0.003619     0.003238         0.002220     0.002960   \n",
       "\n",
       "   ...  embed_2_90  embed_2_91  embed_2_92  embed_2_93  embed_2_94  \\\n",
       "0  ...   -0.003859    0.004634    0.001525   -0.002609    0.007585   \n",
       "1  ...   -0.001741    0.003078   -0.007457   -0.005970   -0.001380   \n",
       "2  ...   -0.001257    0.005854    0.005131   -0.001131    0.013715   \n",
       "3  ...   -0.006106    0.008723   -0.000233   -0.006760    0.011987   \n",
       "4  ...   -0.013453    0.007337   -0.016623    0.000291    0.008107   \n",
       "\n",
       "   embed_2_95  embed_2_96  embed_2_97  embed_2_98  embed_2_99  \n",
       "0    0.003990   -0.005448   -0.000517   -0.008588    0.001712  \n",
       "1   -0.001512   -0.003999   -0.005291   -0.003582   -0.002984  \n",
       "2    0.012943   -0.009549   -0.006825   -0.006487    0.005322  \n",
       "3    0.008103   -0.006340   -0.005677   -0.006845    0.006009  \n",
       "4    0.017724   -0.010720   -0.009756   -0.016503   -0.000963  \n",
       "\n",
       "[5 rows x 1758 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se crea un dataframe con el conjunto de características normalizado:\n",
    "\n",
    "data = pd.DataFrame(data_norm, columns=columnas)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, procedemos a dividir el conjunto de datos en datos en un 80% para entrenamiento y 20% para prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora cargamos los modelos que vamos a emplear para la clasificación de los datos, además del método de Validación Cruzada, con el cual prodeceremos a medir el desempeño de los clasificadores en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## se cargan los modelos\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos los tres modelos con los datos de entrenamiento y empleamos validación cruzada, dividiendo el modelo en 5 partes o folds (cv=5). El método de validación cruzada entrena cada modelo con *k-1* folds y lo valida con el fold restante, midiendo la precisión en cada paso. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtiene un rendimiento de 88.3% con Regresión Logística\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtiene un rendimiento de 87.7% con Random Forest\n",
      "Se obtiene un redimiento de 85.2% con SGD\n"
     ]
    }
   ],
   "source": [
    "## Entrenamos el modelo con Regresión logistica\n",
    "\n",
    "# Se ajusta el modelo de Regresión Logística (lr) a los datos y se mide el rendimiento promedio\n",
    "lr = LogisticRegression(C=500) #C=500: 88.3   C=500: 88.0 C=50: 88.3 C=1: 84.6 penalty='l1' demorado\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "score = cross_val_score(lr, X_train, y_train, cv=5) \n",
    "print(\"Se obtiene un rendimiento de {0:.1%} con Regresión Logística\".format(score.mean()))\n",
    "\n",
    "\n",
    "## Entrenamos el modelo de Bosque Aleatorio y medimos el rendimiento promedio\n",
    "rf = RandomForestClassifier(random_state=0)  #no afectación al variar criterion, max depth, n_estimator\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "score = cross_val_score(rf, X_train, y_train, cv=5)\n",
    "print(\"Se obtiene un rendimiento de {0:.1%} con Random Forest\".format(score.mean()))\n",
    "\n",
    "\n",
    "## Entrenamos el modelo de Descenso del Gradiente Estocástico y medimos el rendimiento promedio\n",
    "sgd = linear_model.SGDClassifier(max_iter=1000, tol=1e-3) \n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "score = cross_val_score(sgd, X_train, y_train, cv=5)\n",
    "print(\"Se obtiene un redimiento de {0:.1%} con SGD\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que se obtiene un mayor rendimiento en el conjunto de entrenamiento con el modelo de Regresión Logística, seguido de Random Forest y por último SGD. Sin embargo, la variación entre el rendimiento de los 3 modelos no es muy significativa. \n",
    "\n",
    "Utilizamos las métricas precision, recall, F1-score y confusion matrix para medir el desempeño de los clasifidores en el conjunto de prueba. \n",
    "\n",
    "La **matriz de confusión** nos compara las predicciones con los datos reales, donde cada columna de la matriz representa el número de predicciones de cada clase, mientras que las filas represetan la clase real. El **precision** nos mide la capacidad del clasificador para no clasificar como positiva una muestra negativa. El **recall** mide la capacidad del clasificador para clasificar las muestras positivas. El **f1-score** es el promedio balaceado entre *precision* y *recall*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtiene una precisión de 88.8% con Regresión Logística\n",
      "Se obtiene una precisión de 88.1% con Random Forest\n",
      "Se obtiene una precisión de 86.4% con SGD\n",
      "\n",
      "Se obtiene un recall de 88.8% con Regresión Logística\n",
      "Se obtiene un recall de 87.6% con Random Forest\n",
      "Se obtiene un recall de 84.4% con SGD\n",
      "\n",
      "Se obtiene un F1-score de 88.8% con Regresión Logística\n",
      "Se obtiene un F1-score de 87.2% con Random Forest\n",
      "Se obtiene un F1-score de 83.4% con SGD\n"
     ]
    }
   ],
   "source": [
    "## Evaluación de los clasificadores\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "##Precision\n",
    "lr_score = precision_score(y_test, lr.predict(X_test), average='weighted')\n",
    "rf_score = precision_score(y_test, rf.predict(X_test), average='weighted')\n",
    "sgd_score = precision_score(y_test, sgd.predict(X_test), average='weighted')\n",
    "\n",
    "print(\"Se obtiene una precisión de {0:.1%} con Regresión Logística\".format(lr_score))\n",
    "print(\"Se obtiene una precisión de {0:.1%} con Random Forest\".format(rf_score))\n",
    "print(\"Se obtiene una precisión de {0:.1%} con SGD\\n\".format(sgd_score))\n",
    "\n",
    "\n",
    "##Recall\n",
    "lr_score = recall_score(y_test, lr.predict(X_test), average='weighted')\n",
    "rf_score = recall_score(y_test, rf.predict(X_test), average='weighted')\n",
    "sgd_score = recall_score(y_test, sgd.predict(X_test), average='weighted')\n",
    "\n",
    "print(\"Se obtiene un recall de {0:.1%} con Regresión Logística\".format(lr_score))\n",
    "print(\"Se obtiene un recall de {0:.1%} con Random Forest\".format(rf_score))\n",
    "print(\"Se obtiene un recall de {0:.1%} con SGD\\n\".format(sgd_score))\n",
    "\n",
    "\n",
    "##F1_score\n",
    "lr_score = f1_score(y_test, lr.predict(X_test), average='weighted')\n",
    "rf_score = f1_score(y_test, rf.predict(X_test), average='weighted')\n",
    "sgd_score = f1_score(y_test, sgd.predict(X_test), average='weighted')\n",
    "\n",
    "print(\"Se obtiene un F1-score de {0:.1%} con Regresión Logística\".format(lr_score))\n",
    "print(\"Se obtiene un F1-score de {0:.1%} con Random Forest\".format(rf_score))\n",
    "print(\"Se obtiene un F1-score de {0:.1%} con SGD\".format(sgd_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión Regresión Lineal:\n",
      " [[2782  211]\n",
      " [ 316 1416]] \n",
      "\n",
      "Matriz de confusión Random Forest:\n",
      " [[2881  112]\n",
      " [ 474 1258]] \n",
      "\n",
      "Matriz de confusión SGD:\n",
      " [[2943   50]\n",
      " [ 685 1047]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Confusion matrix\n",
    "lr_cf = confusion_matrix(y_test, lr.predict(X_test))\n",
    "print(\"Matriz de confusión Regresión Lineal:\\n\", lr_cf, \"\\n\")\n",
    "\n",
    "rf_cf = confusion_matrix(y_test, rf.predict(X_test))\n",
    "print(\"Matriz de confusión Random Forest:\\n\", rf_cf, \"\\n\")\n",
    "\n",
    "sgd_cf = confusion_matrix(y_test, sgd.predict(X_test))\n",
    "print(\"Matriz de confusión SGD:\\n\", sgd_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el conjunto de entrenamiento, los modelos de Regresión Logística y Bosque Aleatorio muestran un rendimiento similar respecto a cada métrica, mientras que el modelo SGD muestra un desempeño más bajo a la hora de clasificar las clases de péptidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando selección de características\n",
    "\n",
    "A continuación se aplica un método de selección de carasterísticas sobre los datos y luego se miden las métricas para cada modelo. Esto con el objetivo de identificar si extrayendo las características principales significa una mejora en la capacidad de clasificación de los modelos. \n",
    "\n",
    "Para ello se utiliza un Eliminador de Características Recursivo, *RFE*, por sus siglas en inglés, al cual se le ingresa el número de características máximo que queremos seleccionar. \n",
    "\n",
    "\n",
    "De manera aleatoria se ha decidido probar cada modelo al seleccionar solo 1000, 500 y 100 características. En cada caso se mide el *Accuracy* con objetivo de comparar el desempeño de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFE con Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionando 1000 características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1758 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1658 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1558 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1458 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1358 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1258 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1158 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1058 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.0% accuracy on test set.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# se crea modelo con Regresión Logística y se seleccionan 1000 características, eliminando 100 a cada paso\n",
    "rfe_lr1 = RFE(estimator=lr, n_features_to_select=1000, step = 100, verbose=1)\n",
    "\n",
    "#Ajustando modelo a datos\n",
    "rfe_lr1.fit(X_train, y_train)\n",
    "\n",
    "#calculamos el accuracy\n",
    "\n",
    "acc = accuracy_score(y_test, rfe_lr1.predict(X_test))\n",
    "print(\"{0:.1%} accuracy on test set.\".format(acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionando 500 características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1758 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1558 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1358 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1158 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 958 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 758 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 558 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.9% accuracy on test set.\n"
     ]
    }
   ],
   "source": [
    "# se crea modelo con Regresión Logística y se seleccionan 500 características, eliminando 200 a cada paso. \n",
    "rfe_lr2 = RFE(estimator=lr, n_features_to_select=500, step = 200, verbose=1)\n",
    "\n",
    "#Ajustando modelo a datos\n",
    "rfe_lr2.fit(X_train, y_train)\n",
    "\n",
    "#calculamos el accuracy\n",
    "\n",
    "acc = accuracy_score(y_test, rfe_lr2.predict(X_test))\n",
    "print(\"{0:.1%} accuracy on test set.\".format(acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionando 100 características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1758 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1458 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1158 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 858 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 558 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 258 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.3% accuracy on test set.\n"
     ]
    }
   ],
   "source": [
    "# se crea modelo con Regresión Logística y se seleccionan 1000 características\n",
    "rfe_lr3 = RFE(estimator=lr, n_features_to_select=100, step = 300, verbose=1)\n",
    "\n",
    "#Ajustando modelo a datos\n",
    "rfe_lr3.fit(X_train, y_train)\n",
    "\n",
    "#calculamos el accuracy\n",
    "\n",
    "acc = accuracy_score(y_test, rfe_lr3.predict(X_test))\n",
    "print(\"{0:.1%} accuracy on test set.\".format(acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se presenta un cambio muy significativo en la exactitud del modelo al seleccionar 1000 o 500 características. Mientras que al seleccionar 100 características, la capacidad de clasificación del modelo de Regresión Logística baja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFE con modelo de Bosque Aleatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionando 1000 características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1758 features.\n",
      "Fitting estimator with 1658 features.\n",
      "Fitting estimator with 1558 features.\n",
      "Fitting estimator with 1458 features.\n",
      "Fitting estimator with 1358 features.\n",
      "Fitting estimator with 1258 features.\n",
      "Fitting estimator with 1158 features.\n",
      "Fitting estimator with 1058 features.\n",
      "88.1% accuracy on test set.\n"
     ]
    }
   ],
   "source": [
    "# se crea modelo con Random Forest y se seleccionan 1000 características, eliminando 100 a cada paso\n",
    "rfe_rf1 = RFE(estimator=rf, n_features_to_select=1000, step = 100, verbose=1)\n",
    "\n",
    "#Ajustando modelo a datos\n",
    "rfe_rf1.fit(X_train, y_train)\n",
    "\n",
    "#calculamos el accuracy\n",
    "\n",
    "acc = accuracy_score(y_test, rfe_rf1.predict(X_test))\n",
    "print(\"{0:.1%} accuracy on test set.\".format(acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionando 500 características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1758 features.\n",
      "Fitting estimator with 1558 features.\n",
      "Fitting estimator with 1358 features.\n",
      "Fitting estimator with 1158 features.\n",
      "Fitting estimator with 958 features.\n",
      "Fitting estimator with 758 features.\n",
      "Fitting estimator with 558 features.\n",
      "88.0% accuracy on test set.\n"
     ]
    }
   ],
   "source": [
    "# se crea modelo con Random Forest y se seleccionan 500 características, eliminando 200 a cada paso\n",
    "rfe_rf2 = RFE(estimator=rf, n_features_to_select=500, step = 200, verbose=1)\n",
    "\n",
    "#Ajustando modelo a datos\n",
    "rfe_rf2.fit(X_train, y_train)\n",
    "\n",
    "#calculamos el accuracy\n",
    "\n",
    "acc = accuracy_score(y_test, rfe_rf2.predict(X_test))\n",
    "print(\"{0:.1%} accuracy on test set.\".format(acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionando 100 características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1758 features.\n",
      "Fitting estimator with 1458 features.\n",
      "Fitting estimator with 1158 features.\n",
      "Fitting estimator with 858 features.\n",
      "Fitting estimator with 558 features.\n",
      "Fitting estimator with 258 features.\n",
      "89.2% accuracy on test set.\n"
     ]
    }
   ],
   "source": [
    "# se crea modelo con Random Forest y se seleccionan 100 características, eliminando 300 a cada paso\n",
    "rfe_rf3 = RFE(estimator=rf, n_features_to_select=100, step = 300, verbose=1)\n",
    "\n",
    "#Ajustando modelo a datos\n",
    "rfe_rf3.fit(X_train, y_train)\n",
    "\n",
    "#calculamos el accuracy\n",
    "\n",
    "acc = accuracy_score(y_test, rfe_rf3.predict(X_test))\n",
    "print(\"{0:.1%} accuracy on test set.\".format(acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvo una mejor capacidad de clasifición (89.2%) con el modelo al seleccionar el menor número de características. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFE con Descenso de Gradiente Estocástico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionando 1000 características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1758 features.\n",
      "Fitting estimator with 1658 features.\n",
      "Fitting estimator with 1558 features.\n",
      "Fitting estimator with 1458 features.\n",
      "Fitting estimator with 1358 features.\n",
      "Fitting estimator with 1258 features.\n",
      "Fitting estimator with 1158 features.\n",
      "Fitting estimator with 1058 features.\n",
      "84.8% accuracy on test set.\n"
     ]
    }
   ],
   "source": [
    "# se crea modelo con SGD y se seleccionan 1000 características, eliminando 100 a cada paso\n",
    "rfe_sgd1 = RFE(estimator=sgd, n_features_to_select=1000, step = 100, verbose=1)\n",
    "\n",
    "#Ajustando modelo a datos\n",
    "rfe_sgd1.fit(X_train, y_train)\n",
    "\n",
    "#calculamos el accuracy\n",
    "\n",
    "acc = accuracy_score(y_test, rfe_sgd1.predict(X_test))\n",
    "print(\"{0:.1%} accuracy on test set.\".format(acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionando 500 características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1758 features.\n",
      "Fitting estimator with 1558 features.\n",
      "Fitting estimator with 1358 features.\n",
      "Fitting estimator with 1158 features.\n",
      "Fitting estimator with 958 features.\n",
      "Fitting estimator with 758 features.\n",
      "Fitting estimator with 558 features.\n",
      "84.3% accuracy on test set.\n"
     ]
    }
   ],
   "source": [
    "# se crea modelo con SGD y se seleccionan 500 características, eliminando 200 a cada paso\n",
    "rfe_sgd2 = RFE(estimator=sgd, n_features_to_select=500, step = 200, verbose=1)\n",
    "\n",
    "#Ajustando modelo a datos\n",
    "rfe_sgd2.fit(X_train, y_train)\n",
    "\n",
    "#calculamos el accuracy\n",
    "\n",
    "acc = accuracy_score(y_test, rfe_sgd2.predict(X_test))\n",
    "print(\"{0:.1%} accuracy on test set.\".format(acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionando 100 características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1758 features.\n",
      "Fitting estimator with 1458 features.\n",
      "Fitting estimator with 1158 features.\n",
      "Fitting estimator with 858 features.\n",
      "Fitting estimator with 558 features.\n",
      "Fitting estimator with 258 features.\n",
      "82.7% accuracy on test set.\n"
     ]
    }
   ],
   "source": [
    "# se crea modelo con SGD y se seleccionan 100 características, eliminando 300 a cada paso\n",
    "rfe_sgd3 = RFE(estimator=sgd, n_features_to_select=100, step = 300, verbose=1)\n",
    "\n",
    "#Ajustando modelo a datos\n",
    "rfe_sgd3.fit(X_train, y_train)\n",
    "\n",
    "#calculamos el accuracy\n",
    "\n",
    "acc = accuracy_score(y_test, rfe_sgd3.predict(X_test))\n",
    "print(\"{0:.1%} accuracy on test set.\".format(acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se alcanzó un *accuracy* de 84.8% al seleccionar 1000 características, y fue dismiuyendo a medida que se seleccionaron menos características para la clasificación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamos los casos en que se tuvo un mejor accuracy para medir las métricas de *precision*, *recall*, *f1-score* y *confusion matrix*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtiene una precisión de 89.0% con Regresión Logística\n",
      "Se obtiene una precisión de 89.4% con Random Forest\n",
      "Se obtiene una precisión de 86.6% con SGD\n",
      "\n",
      "Se obtiene un recall de 89.0% con Regresión Logística\n",
      "Se obtiene un recall de 89.2% con Random Forest\n",
      "Se obtiene un recall de 84.8% con SGD\n",
      "\n",
      "Se obtiene un F1-score de 88.9% con Regresión Logística\n",
      "Se obtiene un F1-score de 89.0% con Random Forest\n",
      "Se obtiene un F1-score de 83.9% con SGD\n"
     ]
    }
   ],
   "source": [
    "## Evaluación de los clasificadores\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "##Precision\n",
    "lr_score = precision_score(y_test, rfe_lr1.predict(X_test), average='weighted')\n",
    "rf_score = precision_score(y_test, rfe_rf3.predict(X_test), average='weighted')\n",
    "sgd_score = precision_score(y_test, rfe_sgd1.predict(X_test), average='weighted')\n",
    "\n",
    "print(\"Se obtiene una precisión de {0:.1%} con Regresión Logística\".format(lr_score))\n",
    "print(\"Se obtiene una precisión de {0:.1%} con Random Forest\".format(rf_score))\n",
    "print(\"Se obtiene una precisión de {0:.1%} con SGD\\n\".format(sgd_score))\n",
    "\n",
    "\n",
    "##Recall\n",
    "lr_score = recall_score(y_test, rfe_lr1.predict(X_test), average='weighted')\n",
    "rf_score = recall_score(y_test, rfe_rf3.predict(X_test), average='weighted')\n",
    "sgd_score = recall_score(y_test, rfe_sgd1.predict(X_test), average='weighted')\n",
    "\n",
    "print(\"Se obtiene un recall de {0:.1%} con Regresión Logística\".format(lr_score))\n",
    "print(\"Se obtiene un recall de {0:.1%} con Random Forest\".format(rf_score))\n",
    "print(\"Se obtiene un recall de {0:.1%} con SGD\\n\".format(sgd_score))\n",
    "\n",
    "\n",
    "##F1_score\n",
    "lr_score = f1_score(y_test, rfe_lr1.predict(X_test), average='weighted')\n",
    "rf_score = f1_score(y_test, rfe_rf3.predict(X_test), average='weighted')\n",
    "sgd_score = f1_score(y_test, rfe_sgd1.predict(X_test), average='weighted')\n",
    "\n",
    "print(\"Se obtiene un F1-score de {0:.1%} con Regresión Logística\".format(lr_score))\n",
    "print(\"Se obtiene un F1-score de {0:.1%} con Random Forest\".format(rf_score))\n",
    "print(\"Se obtiene un F1-score de {0:.1%} con SGD\".format(sgd_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión Regresión Lineal:\n",
      " [[2782  211]\n",
      " [ 308 1424]] \n",
      "\n",
      "Matriz de confusión Random Forest:\n",
      " [[2857  136]\n",
      " [ 373 1359]] \n",
      "\n",
      "Matriz de consufión SGD:\n",
      " [[2938   55]\n",
      " [ 661 1071]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Confusion matrix\n",
    "lr_cf = confusion_matrix(y_test, rfe_lr1.predict(X_test))\n",
    "print(\"Matriz de confusión Regresión Lineal:\\n\", lr_cf, \"\\n\")\n",
    "\n",
    "rf_cf = confusion_matrix(y_test, rfe_rf3.predict(X_test))\n",
    "print(\"Matriz de confusión Random Forest:\\n\", rf_cf, \"\\n\")\n",
    "\n",
    "sgd_cf = confusion_matrix(y_test, rfe_sgd1.predict(X_test))\n",
    "print(\"Matriz de consufión SGD:\\n\", sgd_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al aplicar un método de selección de características, donde se tomal 1000 para los modelos de Regresión Logística y SGD, y 100 características para el modelo de Bosque Aleatorio, se obtuvo una ligera mejora en las métricas de los modelos de Regresión Logística y Bosque Aleatorio, mientras que no se observó mejora alguna con el modelo de Descenso de Gradiente Estocástico. \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando extracción de características\n",
    "\n",
    "A continuación se aplica un método de selección de carasterísticas sobre los datos y luego se miden las métricas para cada modelo. Como en el caso anterior, se evalúa cada modelo extrayendo 1000, 500 y 100 componentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.2% test set accuracy\n"
     ]
    }
   ],
   "source": [
    "# Pipeline con Regresión Lineal\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "        ('reducer', PCA(n_components=1000)),\n",
    "        ('classifier', LogisticRegression())])\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "# Score the accuracy on the test set\n",
    "accuracy = pipe_lr.score(X_test, y_test)\n",
    "\n",
    "# Prints the model accuracy\n",
    "print('{0:.1%} test set accuracy'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.3% test set accuracy\n"
     ]
    }
   ],
   "source": [
    "# Pipeline con Random Forest\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "        ('reducer', PCA(n_components=1000)),\n",
    "        ('classifier', RandomForestClassifier())])\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "# Score the accuracy on the test set\n",
    "accuracy = pipe_rf.score(X_test, y_test)\n",
    "\n",
    "# Prints the model accuracy\n",
    "print('{0:.1%} test set accuracy'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.3% test set accuracy\n"
     ]
    }
   ],
   "source": [
    "# Pipeline con SGD\n",
    "\n",
    "pipe_sgd = Pipeline([\n",
    "        ('reducer', PCA(n_components=1000)),\n",
    "        ('classifier', linear_model.SGDClassifier())])\n",
    "\n",
    "pipe_sgd.fit(X_train, y_train)\n",
    "\n",
    "# Score the accuracy on the test set\n",
    "accuracy = pipe_sgd.score(X_test, y_test)\n",
    "\n",
    "# Prints the model accuracy\n",
    "print('{0:.1%} test set accuracy'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtiene una precisión de 86.3% con Regresión Logística\n",
      "Se obtiene una precisión de 77.2% con Random Forest\n",
      "Se obtiene una precisión de 86.7% con SGD\n",
      "\n",
      "Se obtiene un recall de 85.2% con Regresión Logística\n",
      "Se obtiene un recall de 76.3% con Random Forest\n",
      "Se obtiene un recall de 86.3% con SGD\n",
      "\n",
      "Se obtiene un F1-score de 84.5% con Regresión Logística\n",
      "Se obtiene un F1-score de 74.4% con Random Forest\n",
      "Se obtiene un F1-score de 85.9% con SGD\n"
     ]
    }
   ],
   "source": [
    "## Evaluación de los clasificadores\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "##Precision\n",
    "lr_score = precision_score(y_test, pipe_lr.predict(X_test), average='weighted')\n",
    "rf_score = precision_score(y_test, pipe_rf.predict(X_test), average='weighted')\n",
    "sgd_score = precision_score(y_test, pipe_sgd.predict(X_test), average='weighted')\n",
    "\n",
    "print(\"Se obtiene una precisión de {0:.1%} con Regresión Logística\".format(lr_score))\n",
    "print(\"Se obtiene una precisión de {0:.1%} con Random Forest\".format(rf_score))\n",
    "print(\"Se obtiene una precisión de {0:.1%} con SGD\\n\".format(sgd_score))\n",
    "\n",
    "\n",
    "##Recall\n",
    "lr_score = recall_score(y_test, pipe_lr.predict(X_test), average='weighted')\n",
    "rf_score = recall_score(y_test, pipe_rf.predict(X_test), average='weighted')\n",
    "sgd_score = recall_score(y_test,pipe_sgd.predict(X_test), average='weighted')\n",
    "\n",
    "print(\"Se obtiene un recall de {0:.1%} con Regresión Logística\".format(lr_score))\n",
    "print(\"Se obtiene un recall de {0:.1%} con Random Forest\".format(rf_score))\n",
    "print(\"Se obtiene un recall de {0:.1%} con SGD\\n\".format(sgd_score))\n",
    "\n",
    "\n",
    "##F1_score\n",
    "lr_score = f1_score(y_test, pipe_lr.predict(X_test), average='weighted')\n",
    "rf_score = f1_score(y_test, pipe_rf.predict(X_test), average='weighted')\n",
    "sgd_score = f1_score(y_test, pipe_sgd.predict(X_test), average='weighted')\n",
    "\n",
    "print(\"Se obtiene un F1-score de {0:.1%} con Regresión Logística\".format(lr_score))\n",
    "print(\"Se obtiene un F1-score de {0:.1%} con Random Forest\".format(rf_score))\n",
    "print(\"Se obtiene un F1-score de {0:.1%} con SGD\".format(sgd_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión Regresión Lineal:\n",
      " [[2901   92]\n",
      " [ 607 1125]] \n",
      "\n",
      "Matriz de confusión Random Forest:\n",
      " [[2801  192]\n",
      " [ 926  806]] \n",
      "\n",
      "Matriz de consufión SGD:\n",
      " [[2859  134]\n",
      " [ 513 1219]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Confusion matrix\n",
    "lr_cf = confusion_matrix(y_test, pipe_lr.predict(X_test))\n",
    "print(\"Matriz de confusión Regresión Lineal:\\n\", lr_cf, \"\\n\")\n",
    "\n",
    "rf_cf = confusion_matrix(y_test, pipe_rf.predict(X_test))\n",
    "print(\"Matriz de confusión Random Forest:\\n\", rf_cf, \"\\n\")\n",
    "\n",
    "sgd_cf = confusion_matrix(y_test, pipe_sgd.predict(X_test))\n",
    "print(\"Matriz de consufión SGD:\\n\", sgd_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
